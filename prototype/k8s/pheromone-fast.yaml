apiVersion: apps/v1
kind: Deployment
metadata:
  name: aswarm-pheromone
  namespace: aswarm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: aswarm-pheromone
  template:
    metadata:
      labels:
        app: aswarm-pheromone
    spec:
      priorityClassName: system-cluster-critical  # Higher scheduling priority
      serviceAccountName: aswarm-sa
      containers:
      - name: aggregator
        image: python:3.11-slim
        env:
        - name: ELEVATE_THRESHOLD
          value: "5"              # Lower threshold for faster detection
        - name: SIGNAL_WINDOW_MS
          value: "500"            # 500ms sliding window
        - name: POLL_MS
          value: "100"            # Poll every 100ms
        command: ["bash","-c"]
        args:
        - |
          pip install --no-cache-dir kubernetes
          python - <<'PY'
          import os, time, json, sys
          from datetime import datetime, timezone
          from kubernetes import client, config
          from collections import deque
          
          # in-cluster config
          config.load_incluster_config()
          v1 = client.CoreV1Api()
          ns = "aswarm"
          
          # Configuration from env
          threshold = int(os.environ.get("ELEVATE_THRESHOLD", "5"))
          window_ms = int(os.environ.get("SIGNAL_WINDOW_MS", "500"))
          poll_ms = int(os.environ.get("POLL_MS", "100"))
          scenario_id = os.environ.get("SCENARIO_ID", "portscan-fanout")
          
          # Get run_id from anomaly job annotation
          run_id = None
          
          # Sliding window for event tracking (using perf_counter for accuracy)
          event_window = deque()
          elevated = False
          last_elevation = 0
          
          print(f"Pheromone starting: threshold={threshold}, window_ms={window_ms}, poll_ms={poll_ms}", flush=True)
          
          while True:
              start_time = time.perf_counter()
              current_time = time.time()
              
              # Try to get run_id from latest anomaly job
              if not run_id:
                  try:
                      jobs = v1.list_namespaced_job(ns, label_selector="app=anomaly")
                      if jobs.items:
                          latest_job = sorted(jobs.items, key=lambda j: j.metadata.creation_timestamp)[-1]
                          run_id = latest_job.metadata.annotations.get("run_id", 
                                  datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ"))
                  except:
                      run_id = datetime.now(timezone.utc).strftime("%Y%m%dT%H%M%SZ")
              
              # Remove old events outside window
              window_start = current_time - (window_ms / 1000.0)
              while event_window and event_window[0]["time"] < window_start:
                  event_window.popleft()
              
              # Count recent 'PORTSCAN' events from anomaly pods via logs
              pods = v1.list_namespaced_pod(ns, label_selector="app=anomaly").items
              witness_pods = set()
              new_events = 0
              
              for p in pods:
                  if p.status.phase != "Running":
                      continue
                  try:
                      # Read only last 10 lines for speed
                      lg = v1.read_namespaced_pod_log(p.metadata.name, ns, tail_lines=10)
                      pod_events = lg.count("PORTSCAN")
                      if pod_events > 0:
                          witness_pods.add(p.metadata.name)
                          # Add events to window
                          for _ in range(pod_events):
                              event_window.append({
                                  "time": current_time,
                                  "pod": p.metadata.name,
                                  "type": "PORTSCAN"
                              })
                          new_events += pod_events
                  except Exception as e:
                      pass
              
              # Current count in window
              window_count = len(event_window)
              
              # Elevation with hysteresis (prevent flapping)
              if window_count >= threshold and not elevated and (current_time - last_elevation) > 2:
                  elevated = True
                  last_elevation = current_time
                  ts = datetime.now(timezone.utc).isoformat()
                  
                  # Rich elevation data
                  elevation_data = {
                      "elevated": "true",
                      "ts": ts,
                      "count": str(window_count),
                      "window_ms": str(window_ms),
                      "threshold": str(threshold),
                      "witnesses": str(len(witness_pods)),
                      "witness_pods": ",".join(sorted(list(witness_pods)[:5])),
                      "scenario": scenario_id,
                      "pattern": "lateral-scan",
                      "confidence": str(min(100, int(window_count / threshold * 50))),
                      "run_id": run_id
                  }
                  
                  # Create both run-specific and general ConfigMaps
                  for cm_name in [f"aswarm-elevated-{run_id}", "aswarm-elevated"]:
                      cm = client.V1ConfigMap(
                          metadata=client.V1ObjectMeta(
                              name=cm_name,
                              labels={"type": "elevation", "run_id": run_id}
                          ),
                          data=elevation_data
                      )
                      
                      try:
                          v1.create_namespaced_config_map(ns, cm)
                      except client.exceptions.ApiException as e:
                          if e.status == 409:  # Already exists
                              v1.patch_namespaced_config_map(cm_name, ns, cm)
                  
                  print(json.dumps({
                      "action": "elevation_created",
                      "elevated": True,
                      "ts": ts,
                      "count": window_count,
                      "witnesses": len(witness_pods),
                      "scenario": scenario_id,
                      "run_id": run_id,
                      "detection_ms": (time.perf_counter() - start_time) * 1000
                  }), flush=True)
              
              # Reset elevation after window expires
              elif window_count < threshold and elevated:
                  elevated = False
              
              # Sleep for precise polling interval
              elapsed = (time.perf_counter() - start_time) * 1000
              sleep_time = max(0, (poll_ms - elapsed) / 1000.0)
              time.sleep(sleep_time)
          PY
        resources:
          requests:
            cpu: "250m"      # More CPU for faster processing
            memory: "128Mi"
          limits:
            cpu: "1"
            memory: "256Mi"